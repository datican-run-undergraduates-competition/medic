{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa91faae-e42e-408b-8acc-92e835b0a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import math as m\n",
    "\n",
    "cam= cv2.VideoCapture(0)\n",
    "good_frames=0\n",
    "bad_frames= 0\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font2 = cv2.FONT_HERSHEY_DUPLEX\n",
    "fps = cam.get(cv2.CAP_PROP_FPS)\n",
    "# Colors.\n",
    "blue = (255, 127, 0)\n",
    "red = (50, 50, 255)\n",
    "green = (127, 255, 0)\n",
    "dark_blue = (127, 20, 0)\n",
    "light_green = (127, 233, 100)\n",
    "yellow = (0, 255, 255)\n",
    "pink = (255, 0, 255)\n",
    "mp_pose= mp.solutions.pose\n",
    "mp_holistic= mp.solutions.holistic\n",
    "pose = mp_pose.Pose()\n",
    "def calcangle(x1, y1, x2, y2):\n",
    "    theta = m.acos((y2 -y1)*(-y1) / (m.sqrt((x2 - x1)**2 + (y2 - y1)**2) * y1))\n",
    "    degree = int(180/m.pi)*theta\n",
    "    return degree\n",
    "#find distance between points\n",
    "def calcdistance(x1, y1, x2, y2):\n",
    "    dist = m.sqrt((x2-x1)**2+(y2-y1)**2)\n",
    "    return dist\n",
    "while cam.isOpened():\n",
    "    ret, frame= cam.read()\n",
    "\n",
    "    h,w = frame.shape[:2]\n",
    "    #convert color\n",
    "    image=  cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results= pose.process(image)\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    \n",
    "    if results.pose_landmarks:\n",
    "        lm = results.pose_landmarks\n",
    "        lmPose = mp_pose.PoseLandmark\n",
    "        #Get the points values * frame height and width to get cordinates\n",
    "    #left shoulder\n",
    "        l_shldr_x = int(lm.landmark[lmPose.LEFT_SHOULDER].x * w)\n",
    "        l_shldr_y = int(lm.landmark[lmPose.LEFT_SHOULDER].y * h)\n",
    "    # Right shoulder\n",
    "        r_shldr_x = int(lm.landmark[lmPose.RIGHT_SHOULDER].x * w)\n",
    "        r_shldr_y = int(lm.landmark[lmPose.RIGHT_SHOULDER].y * h)\n",
    "    # Left ear.\n",
    "        l_ear_x = int(lm.landmark[lmPose.LEFT_EAR].x * w)\n",
    "        l_ear_y = int(lm.landmark[lmPose.LEFT_EAR].y * h)\n",
    "    # Left hip.\n",
    "        l_hip_x = int(lm.landmark[lmPose.LEFT_HIP].x * w)\n",
    "        l_hip_y = int(lm.landmark[lmPose.LEFT_HIP].y * h)\n",
    "\n",
    "    #offset between the left and right shoulder\n",
    "        offset= calcdistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n",
    "        if offset<100:\n",
    "            cv2.putText(frame, str(int(offset)) + ' Shoulder aligned', ((10, 60)), font, 0.9, green, 2)\n",
    "        else:\n",
    "            cv2.putText(frame, str(int(offset)) + ' Shoulder not aligned', ((10, 60)), font, 0.9, red, 2)\n",
    "    \n",
    "    #calculate angle between ear and shoulder(Inclination)\n",
    "        neck_incline= calcangle( l_shldr_x, l_shldr_y, l_ear_x, l_ear_y)\n",
    "        torso_incline= calcangle( l_shldr_x, l_shldr_y, l_ear_x, l_ear_y)\n",
    "        angle_text_string = 'Neck : ' + str(int(neck_incline)) + '  Torso : ' + str(int(torso_incline))\n",
    "    # Draw landmarks.\n",
    "        cv2.circle(frame, (l_shldr_x, l_shldr_y), 7, yellow, -1)\n",
    "        cv2.circle(frame, (l_ear_x, l_ear_y), 7, yellow, -1)\n",
    "\n",
    "        cv2.circle(frame, (l_shldr_x, l_shldr_y - 100), 7, yellow, -1)\n",
    "        cv2.circle(frame, (r_shldr_x, r_shldr_y), 7, pink, -1)\n",
    "        cv2.circle(frame, (l_hip_x, l_hip_y), 7, yellow, -1)\n",
    "        cv2.circle(frame, (l_hip_x, l_hip_y - 100), 7, yellow, -1)\n",
    "\n",
    "        if neck_incline < 40 and torso_incline < 10:\n",
    "            bad_frames = 0\n",
    "            good_frames += 1\n",
    "\n",
    "            cv2.putText(frame, angle_text_string, (10, 30), font, 0.9, light_green, 2)\n",
    "            cv2.putText(frame, str(int(neck_incline)), (l_shldr_x + 10, l_shldr_y), font, 0.9, light_green, 2)\n",
    "            cv2.putText(frame, str(int(torso_incline)), (l_hip_x + 10, l_hip_y), font, 0.9, light_green, 2)\n",
    "\n",
    "        # Join landmarks.\n",
    "            cv2.line(frame, (l_shldr_x, l_shldr_y), (l_ear_x, l_ear_y), green, 4)\n",
    "            cv2.line(frame, (l_shldr_x, l_shldr_y), (l_shldr_x, l_shldr_y - 100), green, 4)\n",
    "            cv2.line(frame, (l_hip_x, l_hip_y), (l_shldr_x, l_shldr_y), green, 4)\n",
    "            cv2.line(frame, (l_hip_x, l_hip_y), (l_hip_x, l_hip_y - 100), green, 4)\n",
    "\n",
    "        else:\n",
    "            good_frames = 0\n",
    "            bad_frames += 1\n",
    "\n",
    "            cv2.putText(frame, angle_text_string, (10, 30), font, 0.9, red, 2)\n",
    "            cv2.putText(frame, str(int(neck_incline)), (l_shldr_x + 10, l_shldr_y), font, 0.9, red, 2)\n",
    "            cv2.putText(frame, str(int(torso_incline)), (l_hip_x + 10, l_hip_y), font, 0.9, red, 2)\n",
    "\n",
    "        # Join landmarks.\n",
    "            cv2.line(frame, (l_shldr_x, l_shldr_y), (l_ear_x, l_ear_y), red, 4)\n",
    "            cv2.line(frame, (l_shldr_x, l_shldr_y), (l_shldr_x, l_shldr_y - 100), red, 4)\n",
    "            cv2.line(frame, (l_hip_x, l_hip_y), (l_shldr_x, l_shldr_y), red, 4)\n",
    "            cv2.line(frame, (l_hip_x, l_hip_y), (l_hip_x, l_hip_y - 100), red, 4)\n",
    "        # Calculate the time of remaining in a particular posture.\n",
    "            good_time = (1 / fps) * good_frames\n",
    "            bad_time =  (1 / fps) * bad_frames\n",
    "\n",
    "    # Pose time.\n",
    "            if good_time > 0:\n",
    "                time_string_good = 'Good Posture Time : ' + str(round(good_time, 1)) + 's'\n",
    "                cv2.putText(frame, time_string_good, (10, h - 20), font, 0.9, green, 2)\n",
    "            else:\n",
    "                time_string_bad = 'Bad Posture Time : ' + str(round(bad_time, 1)) + 's'\n",
    "                cv2.putText(frame, time_string_bad, (10, h - 20), font, 0.9, red, 2)\n",
    "\n",
    "    # If you stay in bad posture for more than 3 minutes (180s) send an alert.\n",
    "            if bad_time > 5 and torso_incline>10:\n",
    "                cv2.putText(frame, \"Straigthen your back\", (10, h - 50), font2, 0.9, (255,255,255), 2)\n",
    "            if bad_time > 5 and neck_incline>40:\n",
    "                cv2.putText(frame, \"Raise your head\", (10, h - 80), font2, 0.9, (255,255,255), 2)\n",
    "   \n",
    "    # Display frame\n",
    "    cv2.imshow('Posture analysis', frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7990dc3f-5884-4e8d-abfa-b49384801d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "putText(img, text, org, fontFace, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]]) -> img\n",
       ".   @brief Draws a text string.\n",
       ".   \n",
       ".   The function cv::putText renders the specified text string in the image. Symbols that cannot be rendered\n",
       ".   using the specified font are replaced by question marks. See #getTextSize for a text rendering code\n",
       ".   example.\n",
       ".   \n",
       ".   @param img Image.\n",
       ".   @param text Text string to be drawn.\n",
       ".   @param org Bottom-left corner of the text string in the image.\n",
       ".   @param fontFace Font type, see #HersheyFonts.\n",
       ".   @param fontScale Font scale factor that is multiplied by the font-specific base size.\n",
       ".   @param color Text color.\n",
       ".   @param thickness Thickness of the lines used to draw a text.\n",
       ".   @param lineType Line type. See #LineTypes\n",
       ".   @param bottomLeftOrigin When true, the image data origin is at the bottom-left corner. Otherwise,\n",
       ".   it is at the top-left corner.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv2.putText??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aac05eb-1242-405e-b996-7ed016a00696",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydub'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioSegment\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msoundfile\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydub'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "# URL of the audio file\n",
    "url = \"https://stutterrockstar.files.wordpress.com/2011/05/male-episode-1-with-alan1.mp3\"\n",
    "\n",
    "# Step 1: Download the audio file\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(\"0.mp3\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(\"Downloaded audio as 0.mp3\")\n",
    "else:\n",
    "    raise Exception(f\"Failed to download audio. Status code: {response.status_code}\")\n",
    "\n",
    "# Step 2: Convert MP3 to WAV\n",
    "audio = AudioSegment.from_mp3(\"0.mp3\")\n",
    "audio.export(\"0.wav\", format=\"wav\")\n",
    "print(\"Converted to 0.wav\")\n",
    "\n",
    "# Step 3: Resample WAV to 16000 Hz\n",
    "data, sample_rate = sf.read(\"0.wav\")\n",
    "if sample_rate != 16000:\n",
    "    # Calculate the number of samples for the new sample rate\n",
    "    num_samples = int(len(data) * 16000 / sample_rate)\n",
    "    # Resample using soundfile (linear interpolation)\n",
    "    resampled_data = np.interp(\n",
    "        np.linspace(0, len(data), num_samples),\n",
    "        np.arange(len(data)),\n",
    "        data\n",
    "    ).astype(np.float32)\n",
    "    # Write the resampled audio to a new WAV file\n",
    "    sf.write(\"0_resampled.wav\", resampled_data, 16000)\n",
    "    print(\"Resampled to 16000 Hz and saved as 0_resampled.wav\")\n",
    "else:\n",
    "    print(\"Audio is already at 16000 Hz\")\n",
    "    os.rename(\"0.wav\", \"0_resampled.wav\")\n",
    "\n",
    "# Clean up intermediate files\n",
    "if os.path.exists(\"0.mp3\"):\n",
    "    os.remove(\"0.mp3\")\n",
    "if os.path.exists(\"0.wav\"):\n",
    "    os.remove(\"0.wav\")\n",
    "print(\"Cleaned up intermediate files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f8245-6230-4321-a893-07fcfa7588cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
